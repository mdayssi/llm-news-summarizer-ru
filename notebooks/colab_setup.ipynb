{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0",
      "metadata": {
        "id": "0"
      },
      "outputs": [],
      "source": [
        "# Проверка, что среда Colab активна и доступен GPU\n",
        "!nvidia-smi\n",
        "import torch\n",
        "\n",
        "print(\"torch:\", torch.__version__, \"| CUDA доступна:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1",
      "metadata": {
        "id": "1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2",
      "metadata": {
        "id": "2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/llm-news\"\n",
        "for sub in [\"models\", \"metrics\", \"hf_cache\"]:\n",
        "    os.makedirs(os.path.join(BASE, sub), exist_ok=True)\n",
        "\n",
        "print(\"Созданы/проверены папки:\", os.listdir(BASE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3",
      "metadata": {
        "id": "3"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import sys\n",
        "\n",
        "REPO_URL = \"https://github.com/mdayssi/llm-news-summarizer-ru.git\"\n",
        "REPO_DIR = \"/content/llm-news\"\n",
        "\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    !git clone {REPO_URL} {REPO_DIR}\n",
        "else:\n",
        "    print(\"Репозиторий уже есть:\", REPO_DIR)\n",
        "\n",
        "# Дальше будем работать из корня репо\n",
        "%cd {REPO_DIR}\n",
        "!git rev-parse --short HEAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4",
      "metadata": {
        "id": "4"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "env_path = Path(REPO_DIR) / \".env\"\n",
        "kv = {\n",
        "    \"EXTERNAL_MODELS_DIR\": \"/content/drive/MyDrive/llm-news/models\",\n",
        "    \"EXTERNAL_METRICS_DIR\": \"/content/drive/MyDrive/llm-news/metrics_big\",\n",
        "    \"EXTERNAL_CACHE_DIR\": \"/content/drive/MyDrive/llm-news/hf_cache\",\n",
        "}\n",
        "text = \"\\n\".join([f\"{k}={v}\" for k, v in kv.items()]) + \"\\n\"\n",
        "env_path.write_text(text, encoding=\"utf-8\")\n",
        "\n",
        "print(\".env создано:\")\n",
        "print(env_path.read_text())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5",
      "metadata": {
        "id": "5"
      },
      "outputs": [],
      "source": [
        "%pip -q install --upgrade \\\n",
        "  evaluate rouge-score \\\n",
        "  razdel bitsandbytes\\\n",
        "  python-dotenv pyyaml \\\n",
        "\n",
        "import datasets\n",
        "import torch\n",
        "import transformers\n",
        "import accelerate\n",
        "import rouge_score\n",
        "import evaluate\n",
        "import sentencepiece\n",
        "import razdel\n",
        "import dotenv\n",
        "import yaml\n",
        "import tqdm\n",
        "import bitsandbytes\n",
        "\n",
        "print(\"torch:\", torch.__version__, \"| cuda avail:\", torch.cuda.is_available())\n",
        "print(\"transformers:\", transformers.__version__)\n",
        "print(\"datasets:\", datasets.__version__)\n",
        "print(\"evaluate:\", evaluate.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6",
      "metadata": {
        "id": "6"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "repo_src = \"/content/llm-news/src\"\n",
        "if repo_src not in sys.path:\n",
        "    sys.path.insert(0, repo_src)\n",
        "print(\"sys.path ok\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (llm-news)",
      "language": "python",
      "name": "llm-news"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}