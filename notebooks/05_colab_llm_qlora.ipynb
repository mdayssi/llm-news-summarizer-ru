{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    GenerationConfig,\n",
    "    set_seed,\n",
    ")\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "\n",
    "import src.utils.data as data_utils\n",
    "import src.utils.io as io_utils\n",
    "import src.utils.models as model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "1"
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# EXTERNAL = Path(os.getenv(\"EXTERNAL_STORAGE_DIR\"))\n",
    "ROOT = io_utils.repo_root()\n",
    "SPLIT_DIR = ROOT / \"data/splits\"\n",
    "CONFIG_DIR = ROOT / \"config\"\n",
    "METRIC_DIR = ROOT / \"metrics\"\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2",
    "outputId": "beaeb8b0-53aa-4f37-ebea-06978aa21882"
   },
   "outputs": [],
   "source": [
    "ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "3"
   },
   "outputs": [],
   "source": [
    "IDS_PATH = io_utils.load_yaml(CONFIG_DIR / \"dataset.ids.yml\")[\"splits_ids\"]\n",
    "TRAIN_IDS_PATH = IDS_PATH[\"train_ids\"]\n",
    "VAL_IDS_PATH = IDS_PATH[\"val_ids\"]\n",
    "\n",
    "train_ids = pd.read_csv(ROOT / TRAIN_IDS_PATH, header=None)\n",
    "val_ids = pd.read_csv(ROOT / VAL_IDS_PATH, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566,
     "referenced_widgets": [
      "e853458cb9634082acd6d02ba4add753",
      "0314fcd9216c4b36bd2abb02daafa001",
      "e4906c703df241229a4e042e9f543961",
      "f4a7f53304f24e42b4ed44a136941f24",
      "9e6974d0d9e741fa86ae13d8eed3247e",
      "47f2a75fdebe4069b666a498823f92b9",
      "447f953fba834fe19bd8b56a57f43e4d",
      "7d75abe0fac04fc29a5feb4bcf05de53",
      "1fff97eed8c84c6bac88097ebb107339",
      "c0857a19b6b146c3bd8b8b1bef969fae",
      "ad58ab77ad8343fe97aacd3e7207ace9",
      "b7f2fb60f61a4168b7d4173a0bb58e53",
      "71b85ce35754468681ecb50097a316ae",
      "4a71280aeea6461e9975898ce09c0bbc",
      "3e7ab7938b864ccca00d93d08dbf22f8",
      "7377367788ab4987a99b962d2c30ab70",
      "b46172f62ade412cb837f9cb8f7a8348",
      "ef96bbb9167e4f399911c50cf04e23f4",
      "98a8a834add64851a2ccd77b906cc6b2",
      "e711d58e9cf9422cafd1a009724d4219",
      "6b74a2c8e40a4a1cb775828ea0a92486",
      "96c2856f023640e69677f0a2436ba526",
      "dc840b00f0b54b0591ef1e9aaec8fd36",
      "ca6c5ae073eb48ffbbd4f5bfab552af2",
      "c11b4665a9b54fbcb84d5405adc69aec",
      "8ff22493a82b4ac08bf2eec96c76d022",
      "b5c2e3eba8c14db098c6db5ecaf95fff",
      "20f9d50adf094524afd180f0c8c1a323",
      "83f5db210de94e6e933ff33e49a47c1b",
      "775ade3a876e481c82b2a4b33c68314a",
      "eb916825fa38417d97fbdb23fdade073",
      "d3fd20aff8a84c7b88dcbd86600ce8df",
      "41edbb4d409547a6a0d46d4a7d2e1873",
      "beff6d0b7e444bb5b5eca076d32431bc",
      "b30c872bc4fc414987dcbdf82162d16e",
      "5a4a9aef8fff4bf282618f7258a11edb",
      "965e20d13e12417695db31030fab0b41",
      "bde6e36e38f34b11ab14a0414e500616",
      "dbc2a4531b144f499f04ef743799b11e",
      "16169a3b81fa47d8aaf3af8de1f6f5e8",
      "3e02c70f47494805bd1aae9f9734a62a",
      "aeda20c88de5411d93025955d7b98881",
      "dce69782a81f40fcbf281edfc5f59f34",
      "9df887eedcf6498b9674d952930ae6f8",
      "35fceb0a20da4100b7f50ef5228763fc",
      "071e8448375440c3a9102931821fcabf",
      "76f6c33d5c01460fbe765575937b9b77",
      "38917a6d5b1d4370ae80e548300ec704",
      "37e29515c3444fab89b936270a6a9024",
      "27d7893207d641c48899813da6a6f01e",
      "98fc868fffed4fcd81683fa3ac1fa6bf",
      "a7351460b5ac494eb100b99e9306bc62",
      "7f5d953af11848c9af8f6e1d6ea1963c",
      "3f04894c5ad94fd9b3738cf2ef1fdc0d",
      "deb9622bda3d40b0abeaa483a5eb4f0c",
      "50e7139306124cafb1ad3e32fac52900",
      "7cc9d11a917345eb82bbd69ebdc8e4eb",
      "2763cbfde0f5441692e247072f3f0b2c",
      "70031edfc7c14fe186280bb36b50c3dd",
      "71ccab5198504ddd9ab82f7e9ee3ed87",
      "96a12b6c3c104eb5b223c9dd9acaec2e",
      "d41763d0b2974d77b2de6af1a77082d8",
      "5d9d4c465fc64c8398f5ec5b710e7d18",
      "f39d21a909624981ac1a419c3b75c3a4",
      "c55854dacfcc4675b0fd5dc3ca22e0bf",
      "0541ace0e9c54f6ebcae0f9576cf22ab",
      "63aeddce9d6c41e281a3fb7361be5d03",
      "dc8aae23810a4c20b46669b539bd9563",
      "29fcd28d1a8e4e47a74060a34b7dcf58",
      "131a6ed0360f4030b21116aaf13323c5",
      "d470210e80884a70bbedc8a36d1683cf",
      "f3b5e3ce25bc4d8c8935b45c9e1bbee0",
      "c25f0a36e8e646c69413b036ebc4e1c9",
      "e06340c694b84ce095c10aaf9dad722c",
      "c8a2898f4fd44fc799407f9426a0a477",
      "713f5b6608af46ef9102f8fee4b292b9",
      "adf215a1946a4ed4b8f45da4f9854cd1",
      "80d86e8352764ca09ec4de0d00324ed7",
      "546fc30eab5f49d28ff5b5885ed4f431",
      "91bd5107b2cb410696754d0f2b62f707",
      "305a660237da48eab14c3b10410e27c9",
      "47ed23086e214c7c81386bada97c1f40",
      "d777539340144aebb604d1fc13a9bb15",
      "82c5169ed39647bdb3afd62b7d43e0f0",
      "881d394fcf4c4401bd525ed845e00a1b",
      "c828ce300e0f4252b7b669199334499c",
      "978c1ffd9c0b4448bead297660aba98d",
      "61fce2b98530440897f0a739548ef67e"
     ]
    },
    "id": "4",
    "outputId": "cadc7d3e-75c9-4205-aff5-6289a76dbe04"
   },
   "outputs": [],
   "source": [
    "raw_train = load_dataset(\"IlyaGusev/gazeta\")[\"train\"].to_pandas()\n",
    "raw_val = load_dataset(\"IlyaGusev/gazeta\")[\"validation\"].to_pandas()\n",
    "\n",
    "print(\"raw train shape:\", raw_train.shape, \"raw val shape:\", raw_val.shape)\n",
    "raw_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "5",
    "outputId": "eb6e96e8-8691-4dfb-cb47-d8831b616137"
   },
   "outputs": [],
   "source": [
    "columns = [\"text\", \"summary\"]\n",
    "train = raw_train.loc[train_ids.squeeze(), columns]\n",
    "val = raw_val.loc[val_ids.squeeze(), columns]\n",
    "for col in columns:\n",
    "    train[col] = data_utils.clean(train[col])\n",
    "    val[col] = data_utils.clean(val[col])\n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6",
    "outputId": "2b6a4c3e-a504-4c7b-a7c1-22c6af02f239"
   },
   "outputs": [],
   "source": [
    "MODEL_CFG_PATH = CONFIG_DIR / \"models.params.yml\"\n",
    "model_cfg = None\n",
    "if torch.cuda.is_available():\n",
    "    model_cfg = io_utils.load_yaml(MODEL_CFG_PATH)[\"cuda_model\"]\n",
    "else:\n",
    "    model_cfg = io_utils.load_yaml(MODEL_CFG_PATH)[\"cpu_model\"]\n",
    "\n",
    "model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "7",
    "outputId": "b5488ef9-2056-4f3a-8e4b-cbfa7ca60212"
   },
   "outputs": [],
   "source": [
    "device = model_cfg[\"device\"]\n",
    "model_id = model_cfg[\"model_id\"]\n",
    "n_eval = model_cfg[\"n_eval\"]\n",
    "n_train = model_cfg[\"n_train\"]\n",
    "use_4bit = model_cfg[\"use_4bit\"]\n",
    "device_map = model_cfg[\"device_map\"]\n",
    "torch_dtype = (\n",
    "    torch.bfloat16\n",
    "    if device == \"cuda\" and torch.cuda.is_bf16_supported()\n",
    "    else (torch.float16 if device == \"cuda\" else torch.float32)\n",
    ")\n",
    "\n",
    "subset_val = val.sample(\n",
    "    n=min(n_eval, val.shape[0]), random_state=RANDOM_STATE\n",
    ").reset_index(drop=True)\n",
    "\n",
    "subset_train = train.sample(\n",
    "    n=min(n_train, train.shape[0]), random_state=RANDOM_STATE\n",
    ").reset_index(drop=True)\n",
    "\n",
    "subset_val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "8"
   },
   "outputs": [],
   "source": [
    "quantization_config = None\n",
    "if use_4bit:\n",
    "    try:\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch_dtype,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"bitsandbytes не готов, продолжаем без 4-бит:\", e)\n",
    "        quantization_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433,
     "referenced_widgets": [
      "099ab287f12740f699d8d5ec0135cfe4",
      "9269a199a8f44b6890b7483649999b16",
      "c3e1ffc0037a4b41829f08348a730284",
      "108918a220fa4ee28e33d61b67fc9ca4",
      "1dc0700a62904b16950e00bc63921d1c",
      "1a26128c0d6d43d0866e2549ce4ed27d",
      "84cb7ad680594d3daccc3c2aa81f5466",
      "0e260aa0fa774e27a17cdfcb62602802",
      "b3a4e145555c4ac0883841be9fb71167",
      "521591911f4a4caf9858019ca8e714cc",
      "7ed75cc30c854872b4dc078f110b7a53",
      "73fde9d25de24829800a896cea006d92",
      "92fc421dc55d4a189bffaeac42a38b1c",
      "ef9c3132fa6e4a609e8ef473d525d116",
      "4f5628c9979f4052a9a1ca339e7994e3",
      "fff48471155342ebbbf94c60f6d3b436",
      "f350a0028dc8405aabcc0556d8e6ecc2",
      "c9e57edb4f0b4eff9da312a7ced55204",
      "67483281866a45cb84e40adceb6c787e",
      "569af5ca91f94a67ba8cf63f47b24814",
      "5625a26716cd4c0d8917808c337b3e45",
      "3dc220f5682144edaf0cbc603020208b",
      "9b6afdce86d048f2ae661afe53494297",
      "e5e2984325b241e79e8396792f08fc24",
      "6b79d32246be40ef8c5ef990e130ffcc",
      "d22db68d39d14201a70c3af20b0ea78b",
      "8ea51e0cc9e9459296f34cea7077e9da",
      "a2645eff09aa4964bc6568a4cee46de6",
      "0f6d56b767924419b803529d309bec0c",
      "06b127f15e614afebeb66782b36d0041",
      "fb2b5e1ae064462ea858983e567df8e3",
      "90a47b95f9e84afea5a07ef22013ecef",
      "9eb1e543d60747dd8855ee4ea4712d46",
      "013e4b209ba1425ca56aac67b703f2a4",
      "2b6561ef3d43410a98d1b6ba056ab8fa",
      "60e8ee3be39046c0baf6995cac642dc1",
      "6e154fc956354c2eacda64e2d9474533",
      "df17fe5b5f9f4be4a9a9f1bcb41d4f56",
      "caa958b57c3b41d29d0328e3426fd611",
      "867cd6b3ad3a4ca4ad62ef7f76c66f95",
      "08820c4c05984f39957f5cabcd1524af",
      "15e5861edb3b47e4a164c3092311d22c",
      "b9dd36cc26a94e9891cfdbbf75cba77a",
      "7d9137dba55341cda5eb20c7b6b9be6d",
      "6bb7324b1c6e450e8610ea1c90cce900",
      "c6d53a0c1ff14880869a99014d3b479a",
      "1db6a3a63a04477aba3fca0ef58192dc",
      "a56b22911af14affa35b59aed9c89358",
      "c97660fa28874e36bf1145906222ec57",
      "5b63e891dbf1463eaa4a3448b7180587",
      "566be17906f34020a223d1404ca65a70",
      "386b57fcf5064478b65b24606e67d781",
      "29e848e69b2e4265a1e7ce7154f2d898",
      "17c352533c6542c39a1cc7811355be10",
      "6eca2bd344b34272adb6080ed124b387",
      "04927c046af345c6b728cfebb266ce71",
      "d913f25b5a164735a855d5b9df05f95a",
      "d392fca0c3b24ecd9ef4e3ddc62d1cc7",
      "4f60e3a61fcb4263a124c62d8f11f77e",
      "d9752d33e95c4011b14814aed1123448",
      "4fa8764440cf4330a16416f9d229c777",
      "83b666615c174016959511b373f34ed3",
      "0ca3b22202e34ce7be9a81b3a902ca82",
      "c941b90ed93d47b2b0bcb5512dc8f1a5",
      "faead39f50c34876a0eb29a26fa4c765",
      "47e8c57aef9a46939bfba007c9483757",
      "9a9d57148da34cc0a6b2cd1960b4f519",
      "415bd717162647f59dc8a774d040974e",
      "88867b744523428d8157adf5512af081",
      "92c9e0aa02f64e04aacfd8907ac9c44c",
      "8555eaf6b49941e9bae16b54a6fafc02",
      "7d80b3955e6844718c68f88b87ee316b",
      "2d4d9ba42ca248fb9fd8bcd5f34702c8",
      "2d6efd73329a4034a6f99549f335e21a",
      "bb32a0c52f424e8aa291fa75d6991803",
      "1b93e8c520324f49a4afb639bb6dfcbb",
      "86c3ff6301ce4a85a751b0d517651ab7",
      "d9783b3088634aef9fbcb66809f88602",
      "9c4c18e94fe748cb806da0815840a703",
      "66284f44f32a4387b0d108937ed5697b",
      "229cf330f846435e9feafd53a9cf1c80",
      "d25ac9c1cbd049188dc6f9bf8b6e0da3",
      "9c8edc7a96da4dc5a3f66469aa71b061",
      "f5787d5e515c4ba987bab55ad8ca7a2d",
      "ba08ed85ff32482c844081aa26525b91",
      "dd5cd4e8770b4fb4962471f4db978669",
      "ac550ca4d18a40909d7d32ad90804b5a",
      "3ee18ebd61bf48ccb53c8de9028bee5b",
      "c5bc550e4b064c719f7ffefbe3ed8115",
      "95500723d822483c977905008e9dcdfe",
      "62e6a45ef5bd42fb995621501ce0b296",
      "4d8593d90d644eb1a4591cb266033261",
      "f3fb15b163b84175b96f83f18e8acb0d",
      "7900ef9439024ed79e68039ca4e22d26",
      "0ee40f0ba34c4fbaa63424f56ad66e73",
      "17af2fcb78864eff8beb22cab650df28",
      "196b5616152144378bcc12c7457eb409",
      "878fcffeac6c44f78df1b77d58e98280",
      "34c2337cec6e47db96ce2d996b33cec4",
      "40459a42c71b44b8a6496bb647ce84cd",
      "ca0707baa5a7433c883d0155b2c21725",
      "7cd92e7cfdf64ba5865fd9290297525e",
      "272afc58e4a242abbf2e73267c9e0fd3",
      "9f66d56dfe4b448491f3d2afd11d6657",
      "575799d017ab4167b3eb9fec38b664b4",
      "3cf4b1a2b7a3465394b78d79a0f51625",
      "c85d3e35c57241d1b1a630a70f6cb1e3",
      "cc1799dc31ed4731b72f16528efed041",
      "6397fa2bf7004e8890f70a3494cf7166",
      "2ca37738a0da4cc0ab30cea85822ebbd",
      "fcf39bcfd68d452cba5d427bee38fe1d",
      "1ea82fdd2ca1468a954142fcef0b11c7",
      "1af0e8216c30448182e7923d33bf10cf",
      "28af4f64609b45368faeeeace3953e58",
      "ffe3a9ca53f44111b2bca8936d99ab7a",
      "2f02aeb20b6e495485d856249848b042",
      "35af036df0db482eb71a1e6f9c561dce",
      "ca79bb4fabea425d9c3bcb7d92f53638",
      "0bb6082ca9ce4a93bbc98a251a16e1f5",
      "e894dc2ba00b47f1946f0b010a1a3bc6",
      "3111e65657e6458cac1a865244765662",
      "cfafdd4b72fe491d8ce10ef7dd8a29aa",
      "f202d18713e34743aaa89c080cf548de",
      "deb0e0f030c64f669cd45c5296280777",
      "969823b533ad44b8be01ac595f699efb",
      "6ebbab860b2a4c588e81f44276be7e5e",
      "5eda06b6b26e49fda67b5cb2a5489f1e",
      "db2b6ccc042a4a3b879197f573b6acef",
      "685d9a0d8a3a40828a46f27c16e7cca0",
      "2c78fe84efbe4b43875d6286d07a0d93",
      "e1d6a91529554b51accbb2a2a219a0cc",
      "115d5a3513004f39ba7a89c577646144",
      "8a727d278bd24a679ddb97c599e983b8",
      "58888a11c6f443cdba8b06400f722ce2",
      "49d1c3b5a56144f9ad88b5291fcf9ab0",
      "5253b43cfeca40289d4d85c554895c8f",
      "c844ac2e74c849fd843d8d6777f76ba8",
      "f053a38c94dd4ccba977c7d50ae826d2",
      "d9c2d30740b043a791c15085afef2e63",
      "45c0f3b3423f4835bcd05498f336f803",
      "538d0ed49d2c49b4a277245048f8700c",
      "8e1f65aacdfb405da1ce1c70c676510c",
      "97aea276904a47cf8972d1cebab676c9"
     ]
    },
    "id": "9",
    "outputId": "d5aaea73-5071-4900-b509-e9003cf579f9"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device_map=device_map,\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.truncation_side = \"left\"\n",
    "\n",
    "if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "if getattr(model, \"generation_config\", None) is not None:\n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "if device != \"cuda\":\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "10"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"Ты помощник по резюмированию русскоязычных новостей. \"\n",
    "    \"Сделай краткое, нейтральное резюме исходного текста (3–5 предложений). \"\n",
    "    \"Не добавляй фактов, которых нет в тексте.\"\n",
    ")\n",
    "\n",
    "\n",
    "def build_messages(row):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Задача: кратко резюмируй.\\n\\nТекст статьи:\\n{row['text']}\",\n",
    "            },\n",
    "            {\"role\": \"assistant\", \"content\": row[\"summary\"]},\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515,
     "referenced_widgets": [
      "eb1f4eb7c5ae4723bd038e9fd1b6b260",
      "291aaf0e781148f38b4d2f623923f4d1",
      "ed27bfb08b134b28aabda77ad0cc90a8",
      "268f81256feb461498d512006071c9e0",
      "f7338fe9795442f585a64a609a8676ba",
      "bcd743a473c14176a620c01cf35142d4",
      "4d3bdc74f74e408aa6c37c916b98716a",
      "6b221e8e8dff479c98b69cc0c3974ebe",
      "6264a25218064a2cb86f4e176f7f35d6",
      "db467574b25a434c8a6241819b731198",
      "6f3ba6a463324515b1c5fd9049216a46",
      "87e989c41a254813b978f0cedbb91c73",
      "59d1ba0ab02b4a5b8cb5e0382d0df565",
      "9f4bd5dc871f45ffb3de3869f1a29a2c",
      "0eea7e3a5a2747fd94eb32fe45313069",
      "cd6b4d14b75742a49f8cfcae0263b26f",
      "e239bbc2c1c64bf69cb1b838f6b4e5f9",
      "9b09ccb02ec24c52b0860007e99a9c69",
      "8aee7cbeedff4de997a294caec0bef8a",
      "18758068e4e542d8a1fe40d3cf63ab3f",
      "1ea63377498147a88cbb1e9735bdad22",
      "0ac99d3eaa1e43fe9dd206fcbb949d83"
     ]
    },
    "id": "11",
    "outputId": "c1831cf5-a6b1-4a26-b3c6-e0d341be8635"
   },
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(subset_train).map(\n",
    "    build_messages, remove_columns=subset_train.columns.to_list()\n",
    ")\n",
    "val_ds = Dataset.from_pandas(subset_val).map(\n",
    "    build_messages, remove_columns=subset_val.columns.to_list()\n",
    ")\n",
    "\n",
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12",
    "outputId": "010a813e-e236-4b6e-da69-3b98f1766647"
   },
   "outputs": [],
   "source": [
    "peft_cfg = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"gate_proj\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "CHECK_PATH = str(ROOT / \"src/checkpoints\")\n",
    "\n",
    "if getattr(model, \"is_loaded_in_4bit\", False) or getattr(\n",
    "    model, \"is_loaded_in_8bit\", False\n",
    "):\n",
    "    model = prepare_model_for_kbit_training(\n",
    "        model,\n",
    "        use_gradient_checkpointing=True,\n",
    "        gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    )\n",
    "model = get_peft_model(model, peft_cfg)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "fae4d58c8bef416084846fc5671f9e31",
      "22c4a1132d5948218970cbfed607f54b",
      "533712ac551f4588aa83bc35a4eca121",
      "66fb0c0ebab84783bc9faf77bcec6ea5",
      "5af4e348f1ec42b0b66dbc62806696ca",
      "5178c17f73414b3081116d70017980a3",
      "b7a34be67ff14b6982b018794345c216",
      "7f7fc9bd329e404a9efd82fb34b9c41e",
      "e67956c08f114e6dad190eb387f0b702",
      "99540435221945c3ae6b776df49fed96",
      "1799c6dc5fda41c6891f72b64e191e76",
      "b27df130062e4b189de05ccf3d52ca87",
      "17c980d4d12d45cd903f84b4dd2f577d",
      "dd09df12be514ae8b011f8e915f84121",
      "2035117a73354e5bae1f22cd43d34426",
      "89d0114f75da492da9eaaadf0b7256a1",
      "06f70ff6802540048ad0cd00e71ff6c5",
      "eb227813d3314e248e538fdc0e1f120d",
      "e57233212709469493ffed73efe82046",
      "be98d60d542d483aba08d1ece53fcd45",
      "451108ef428644918c9a5007a220b9c3",
      "0a9c636e43f24505a1eadf7f49ee9665",
      "a68f6a9c6b6a4e45ac46c4983684a16e",
      "891d8443ecf24e0a93d826c7de143695",
      "32a03f25463a40099ce77a0b6a3e7681",
      "ac79fa78e3594821868941c519466f38",
      "570f5836ed174616b425b97edc849c1d",
      "2e164a3d2e8c4816ac995793bd0d1a11",
      "f784c01c4f514affa3f6b014d70d32fc",
      "8a152dc550604484bcac547d3a2b2a1c",
      "d8c08a41be2947bbb0307922b77fd18a",
      "c89910f941e3499da512ad7a4df04563",
      "8492ac674bb44ba48a45eead30955362",
      "46c61c463ee24eb1aac0be556c73df98",
      "e9d4c6fa5a4e4247b6d75b334fd1c6aa",
      "acbc0ae0958c4cf893b86cfbfd3b2c15",
      "4ebca19071774ec2bd6cdacd355fa04b",
      "4e57488057704671a18724b235bfb355",
      "3f0aaec1b2f049339fce3b3d05954244",
      "112e5ce368e14048b3580b632586a08f",
      "69455f3d125f4fe497bf890f04da44e0",
      "21dd53b6b00840e6a7819034dba66760",
      "001b7044e05a4269828d059ba52794a5",
      "46dc9f01abd04e63b392b9d211626c7e"
     ]
    },
    "id": "13",
    "outputId": "d45b4393-6aed-4e3c-a15a-9ef72574b0ff"
   },
   "outputs": [],
   "source": [
    "sft_cfg = SFTConfig(\n",
    "    output_dir=CHECK_PATH,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_steps=100,\n",
    "    logging_steps=20,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "    report_to=[],\n",
    "    packing=False,\n",
    "    max_length=2048,\n",
    "    bf16=(device == \"cuda\"),\n",
    "    tf32=(device == \"cuda\"),\n",
    "    optim=(\n",
    "        \"adamw_bnb_8bit\"\n",
    "        if use_4bit\n",
    "        else (\"adamw_torch_fused\" if device == \"cuda\" else \"adamw_torch\")\n",
    "    ),\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    group_by_length=True,\n",
    "    eos_token=tokenizer.eos_token,\n",
    "    dataset_text_field=None,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    args=sft_cfg,\n",
    "    peft_config=peft_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "14",
    "outputId": "a86ee693-d9aa-4f45-a1ff-03e3ddad2e8f"
   },
   "outputs": [],
   "source": [
    "print(\"trainer.model is PeftModel:\", isinstance(trainer.model, PeftModel))\n",
    "print(\"active adapters:\", getattr(trainer.model, \"active_adapters\", None))\n",
    "trainer.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "15",
    "outputId": "1e545c6f-d626-4728-b124-c372f689140e"
   },
   "outputs": [],
   "source": [
    "if hasattr(trainer.model, \"config\"):\n",
    "    trainer.model.config.use_cache = False\n",
    "train_result = trainer.train()\n",
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16",
    "outputId": "d1346467-76f0-406b-dc2d-f86dd10854b3"
   },
   "outputs": [],
   "source": [
    "base_id = model_id\n",
    "\n",
    "for name, cfg in trainer.model.peft_config.items():\n",
    "    cfg.base_model_name_or_path = base_id\n",
    "\n",
    "if hasattr(trainer.model, \"base_model\") and hasattr(trainer.model.base_model, \"config\"):\n",
    "    trainer.model.base_model.config._name_or_path = base_id\n",
    "\n",
    "\n",
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(sft_cfg.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "17",
    "outputId": "144ed547-1581-4e3d-d5bc-599427123952"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "zip_path = \"/content/sft_qwen2_qlora_adapter\"\n",
    "shutil.make_archive(zip_path, \"zip\", sft_cfg.output_dir)\n",
    "files.download(zip_path + \".zip\")\n",
    "\n",
    "!cp -r {sft_cfg.output_dir} \"/content/drive/MyDrive/llm-news\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "99d0a8fb0e024e929801ef1d31ac7caf",
      "bf0734b479d24653bb3fe8c9d789870f",
      "5f9d6cc383cf45919db44dd296e6e6a7",
      "9b38dbb85c57481a8d540c1875cb672d",
      "7c76e6c5e37c497181689399e3de1148",
      "ec0f1a9e5edf406dac19ea3abfecc7e5",
      "7ea3adb82fbb43c7bcf9ca54ad823eae",
      "3526b60a439c44ee90fe1bf039fe9fe3",
      "4bfe61434dc44d8087d8a232349548ab",
      "7491c25937e745b7b6fff078a919dc06",
      "a2ce6a279f0040b0b92a23b2ecb84d6d"
     ]
    },
    "id": "jNnfc5BEBRij",
    "outputId": "1390aa3d-eb3c-4596-eb50-39ad6cf042af"
   },
   "outputs": [],
   "source": [
    "tok = AutoTokenizer.from_pretrained(CHECK_PATH, use_fast=True)\n",
    "\n",
    "model_new = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    CHECK_PATH,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "\n",
    "if hasattr(model_new, \"gradient_checkpointing_disable\"):\n",
    "    model_new.gradient_checkpointing_disable()\n",
    "model_new.config.use_cache = True\n",
    "model_new.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "18"
   },
   "outputs": [],
   "source": [
    "GEN_EVAL = GenerationConfig(\n",
    "    max_new_tokens=200,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "MAX_INPUT_TOKENS = model_utils.get_max_input_tokens(tokenizer, GEN_EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "19"
   },
   "outputs": [],
   "source": [
    "def build_chat(text: str):\n",
    "    msgs = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Задача: кратко резюмируй.\\n\\nТекст статьи:\\n{text}\",\n",
    "        },\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(\n",
    "        msgs, tokenize=False, add_generation_prompt=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "20"
   },
   "outputs": [],
   "source": [
    "def generate_batch(texts, batch_size=4, show_progress=True):\n",
    "    out = []\n",
    "    it = range(0, len(texts), batch_size)\n",
    "    if show_progress:\n",
    "        it = tqdm(\n",
    "            it,\n",
    "            total=math.ceil(len(texts) / batch_size),\n",
    "            desc=\"Generating SFT infer\",\n",
    "            leave=False,\n",
    "        )\n",
    "\n",
    "    for i in it:\n",
    "        chunk = [build_chat(t) for t in texts[i : i + batch_size]]\n",
    "        inputs = tokenizer(\n",
    "            chunk,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            pad_to_multiple_of=8,\n",
    "            max_length=MAX_INPUT_TOKENS,\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_ids = model_new.generate(**inputs, generation_config=GEN_EVAL)\n",
    "\n",
    "        gen_ids = output_ids[:, inputs[\"input_ids\"].shape[1] :]\n",
    "        decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
    "        out.extend([d.strip() for d in decoded])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "f86b0c552d1f48508bca94459d47b86e",
      "45e12e473ba248b5ae9623e16d005ed2",
      "4114924275e34e99a1df54ade012edcb",
      "5189e3f7edcb4300a53f87970f783a8c",
      "2127cfb3a1e84bcdb2df500e013f6cb7",
      "7f930c4d3f6f4a6ca5e53fd0e02c4e6c",
      "561759cc63114617a34bd348786161c1",
      "0376b4afc07a4247b3a723842878b715",
      "6f4d9237e35c419f910de4f19910218f",
      "949a9c1cd67443569e8a119b6f40ed67",
      "8a7d86017fa947c0be68528a791864be"
     ]
    },
    "id": "21",
    "outputId": "b37b33d7-4a31-400d-ee1b-c74255594b26"
   },
   "outputs": [],
   "source": [
    "BATCH = 1 if device != \"cuda\" else 6\n",
    "texts = subset_val[\"text\"].tolist()\n",
    "refs = subset_val[\"summary\"].tolist()\n",
    "preds_sft = generate_batch(texts, batch_size=BATCH, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22",
    "outputId": "4e6282e1-c382-4f13-eb49-2638357605ab"
   },
   "outputs": [],
   "source": [
    "preds_sft[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23",
    "outputId": "ff729197-2863-435a-df20-00e99cd9d6d6"
   },
   "outputs": [],
   "source": [
    "refs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415,
     "referenced_widgets": [
      "8a16b74560f543bcba57ecf62998f179",
      "a7e0ff05b76e421282733cd0ca09a2f1",
      "5aa0713c8acc49faaaa7485ab5cd33c9",
      "126a88ba8ba143a49be86516599e19f2",
      "61c263cb2f9d4c1e9bd15fcedb7ef26a",
      "3b71c45fcf8e48c29913d684ff4867d5",
      "c03a74134dd84521a70f078051bed796",
      "10b5bb65fe9f4be5868f97e5cb8bfaee",
      "f6b44e56868348fb86467c41aedfad1f",
      "60b56c46de364f809f2c32d230f334ef",
      "35a129fb1fd74588af1ba083da4bccf0",
      "7a2a3914d60a460aa82e9a3c0b226af9",
      "dc412ce5084a4ad4a15afdd45e299d0a",
      "7f0cc01d16704cf08e810d29d13e5167",
      "b3adad90493746e4b21ff4d0adcd102e",
      "eed4f2bc4ac44814b2fb675b6aeeb64a",
      "c6a7fb158d3449f2839ea240b5c876b1",
      "fd31ff476f4d4d16b2a58aad8b26687f",
      "5aee5068480444d6b0cfecc13e3fd7cc",
      "b4116f5b85f24093a9d755d7cc13e2cb",
      "afd450fa05634117b58610f9d9bcc6f3",
      "6fcaa960bc5d4773894e130b5e857107",
      "d9b60615eecc4283a9be5f53d8702a97",
      "5aa33fec62ab45e7b803595b638794ac",
      "ed69c9d99b6744f4896553fdad14e939",
      "facd9bf1b86f4c578bb4910c73e3ab4d",
      "210185ffa56d4ae7a83111930b8dd5ec",
      "4c7c351db4ec4c3aa26eddb2d862c17c",
      "aaadbc42c93a4b1fa793c77f1d7f9521",
      "5bb17712acb84190aa7e37aabd025f2c",
      "296b0ce7892042798ae3f2bc73abb8cb",
      "6dc560adb28d44a9942fcfc6a7b06d66",
      "07241bdbce664c7089bf74b54b7b62f8",
      "aec2bc647d4c490ba85a8fa3911a62a8",
      "83f9f49bd6484e47a30be0e121d1b516",
      "6a96754403fd4b1a8ad26c38fabd6483",
      "8954f5d6ba2b478ab9ae06593148fe7b",
      "9ed3c85501904d61a86fe02d0fd75e7a",
      "90ca6dfd0e304e92a749d6994a368c8d",
      "f8ae30d951f84e4f9baeaaddf1318914",
      "65662dbde14a47618f9d38ccde045348",
      "9f4ed920fa81443f9c000052c4f43ebb",
      "e497ba0949b74b8897bad43be675111c",
      "c87b3a70d95949228feb54ab8853cb50",
      "02f8cf7b8bcd41e896c66379a1c46e7d",
      "4c1406f5447547a79e8d76070d06efcf",
      "e8d41ccf922241f285b65099ec4c80c8",
      "4ee1d01040f54d13a46e49a6dd4bf259",
      "5b38d7549ed6488d97eec82de73c2244",
      "7ca5fe33793a4e7895f57ee208b7f10d",
      "afc852a1fa99407ca48dbcdfce72db68",
      "a63caf69ba4a4a4fbf48023e909f58cd",
      "af73f7b422f14bcca4fb9ad8660fe242",
      "9fcebc38bd3c4e679dd75260dbf6b9a3",
      "8751a384a6d94766a902d221f4349ed9",
      "e706c8e363a5400892e33d396bded088",
      "5b30b6c32ba745aa948a1155eb1b0d5d",
      "8ea0f6f19a0747ec8b7c747f0b29b2e1",
      "06430eee1b5e47e88670a4140b395b4d",
      "d137fe63a3f14dd997748207342aa627",
      "9e53cf19910e4f429e42b689af5588da",
      "973b200db1a64f3d90a1fd53b790e957",
      "f32facce9875461a9d08acf452da315b",
      "0fa3732d5ab94c49bccc7cacc6e5eb19",
      "7348bbd46ced4556a25745ad289a09a0",
      "47a227c303c545bc867ee16e4e347d10",
      "0411d1931b8246eea0516e21f7fe95d0",
      "faf28d3e39594d1b8b6a643c0706b1a2",
      "88591ca20d824d8ea9fc2835d41497eb",
      "d53369fd44664fdc9f07af4c330d782a",
      "64ffc547a7964748981be2e770edd353",
      "965760fffa654ac7a3de9401cc034913",
      "a7d8c1e83e1942639dd467d9199fbbf4",
      "6b76eb3892b5487ea89998b3be212fa4",
      "a09c94791196458e86c1643c4b52c616",
      "c83ea7394c6441828579dcee17062cfe",
      "b16a17af07374e9f9f834e27e0fe0215"
     ]
    },
    "id": "24",
    "outputId": "288afbcc-57d7-4def-ca49-1d24cdb803ca"
   },
   "outputs": [],
   "source": [
    "scores = data_utils.get_all_scores(preds_sft, refs, device=device)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "id": "25"
   },
   "outputs": [],
   "source": [
    "Path(METRIC_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_metrics = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"system\": \"SRT QLoRA\",\n",
    "            \"split\": \"validation_full\",\n",
    "            \"rouge1\": scores.get(\"rouge1\", 0.0),\n",
    "            \"rouge2\": scores.get(\"rouge2\", 0.0),\n",
    "            \"rougeL\": scores.get(\"rougeL\", 0.0),\n",
    "            \"rougeLsum\": scores.get(\"rougeLsum\", 0.0),\n",
    "            \"bertscore_precision\": scores.get(\"bertscore_precision\", 0.0),\n",
    "            \"bertscore_recall\": scores.get(\"bertscore_recall\", 0.0),\n",
    "            \"bertscore_f1\": scores.get(\"bertscore_f1\", 0.0),\n",
    "            \"avg_len_pred\": scores.get(\"avg_len_pred\", 0.0),\n",
    "            \"avg_len_ref\": scores.get(\"avg_len_ref\", 0.0),\n",
    "            \"len_ratio_pred_to_ref\": scores.get(\"len_ratio_pred_to_ref\", 0.0),\n",
    "            \"k\": None,\n",
    "            \"n_examples\": n_eval,\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "df_metrics.to_csv(\n",
    "    METRIC_DIR / f\"llm_qlora_validation_{device}_{n_eval}.csv\", index=False\n",
    ")\n",
    "\n",
    "df_sampels = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"title\": subset_val[\"title\"].head(3) if \"title\" in subset_val else [\"\"] * 3,\n",
    "            \"reference\": refs[:3],\n",
    "            \"prediction\": preds_sft[:3],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "df_sampels.to_csv(\n",
    "    METRIC_DIR / f\"llm_qlora_examples_{device}.tsv\", sep=\"\\t\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26",
    "outputId": "4da7d63c-0639-4aca-b4b7-bd654e356aed"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"torch:\", torch.__version__, \"| CUDA доступна:\", torch.cuda.is_available())\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\", force_remount=True)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "\n",
    "BASE = \"/content/drive/MyDrive/llm-news\"\n",
    "for sub in [\"models\", \"metrics\", \"hf_cache\"]:\n",
    "    os.makedirs(os.path.join(BASE, sub), exist_ok=True)\n",
    "\n",
    "print(\"Созданы/проверены папки:\", os.listdir(BASE))\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "REPO_URL = \"https://github.com/mdayssi/llm-news-summarizer-ru.git\"\n",
    "REPO_DIR = \"/content/llm-news\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "else:\n",
    "    print(\"Репозиторий уже есть:\", REPO_DIR)\n",
    "\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "!git rev-parse --short HEAD\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path(REPO_DIR) / \".env\"\n",
    "kv = {\n",
    "    \"EXTERNAL_MODELS_DIR\": \"/content/drive/MyDrive/llm-news/models\",\n",
    "    \"EXTERNAL_METRICS_DIR\": \"/content/drive/MyDrive/llm-news/metrics_big\",\n",
    "    \"EXTERNAL_CACHE_DIR\": \"/content/drive/MyDrive/llm-news/hf_cache\",\n",
    "}\n",
    "text = \"\\n\".join([f\"{k}={v}\" for k, v in kv.items()]) + \"\\n\"\n",
    "env_path.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "print(\".env создано:\")\n",
    "print(env_path.read_text())\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "%pip -q install --upgrade \\\n",
    "  evaluate rouge-score bert_score\\\n",
    "  razdel bitsandbytes accelerate\\\n",
    "  python-dotenv pyyaml peft trl\n",
    "\n",
    "import accelerate\n",
    "import bert_score\n",
    "import bitsandbytes\n",
    "import datasets\n",
    "import dotenv\n",
    "import evaluate\n",
    "import razdel\n",
    "import rouge_score\n",
    "import sentencepiece\n",
    "import torch\n",
    "import tqdm\n",
    "import transformers\n",
    "import yaml\n",
    "\n",
    "print(\"torch:\", torch.__version__, \"| cuda avail:\", torch.cuda.is_available())\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"evaluate:\", evaluate.__version__)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "import sys\n",
    "\n",
    "repo_src = \"/content/llm-news/src\"\n",
    "if repo_src not in sys.path:\n",
    "    sys.path.insert(0, repo_src)\n",
    "print(\"sys.path ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "_of3-SGebUgH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
