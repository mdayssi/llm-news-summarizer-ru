{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    GenerationConfig,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "import src.utils.data as data_utils\n",
    "import src.utils.io as io_utils\n",
    "import src.utils.models as model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1",
    "outputId": "6a2d2839-d7b9-457e-f7bc-2321a40f7d18"
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# EXTERNAL = Path(os.getenv(\"EXTERNAL_STORAGE_DIR\"))\n",
    "ROOT = io_utils.repo_root()\n",
    "SPLIT_DIR = ROOT / \"data/splits\"\n",
    "CONFIG_DIR = ROOT / \"config\"\n",
    "METRIC_DIR = ROOT / \"metrics\"\n",
    "RANDOM_STATE = 42\n",
    "FEWSHOT_POOL_SIZE = 2000\n",
    "FEWSHOT_K = 2\n",
    "OVERHEAD_BUDGET = 128\n",
    "\n",
    "set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2",
    "outputId": "8d75d7f1-2b59-407b-a254-8039a0cacb14"
   },
   "outputs": [],
   "source": [
    "ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "3"
   },
   "outputs": [],
   "source": [
    "IDS_PATH = io_utils.load_yaml(CONFIG_DIR / \"dataset.ids.yml\")[\"splits_ids\"]\n",
    "TRAIN_IDS_PATH = IDS_PATH[\"train_ids\"]\n",
    "VAL_IDS_PATH = IDS_PATH[\"val_ids\"]\n",
    "\n",
    "train_ids = pd.read_csv(ROOT / TRAIN_IDS_PATH, header=None)\n",
    "val_ids = pd.read_csv(ROOT / VAL_IDS_PATH, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 566,
     "referenced_widgets": [
      "9d410deda45c436aba17179e09b7599e",
      "e4ccdee1499a4d78a60fa9d05f6ee6cc",
      "d3a0d6ac37294ae58077c7239ab44438",
      "3bcb3852bb9c407aa940f151b41e16ff",
      "1338e9b3c394427a8fce5438a5ce4b93",
      "67c6280af2cb4e0aa8ec5039030629cb",
      "f061778890a343d8a42ddc2d983fed4b",
      "ce33c9fe59ce417badfb9eec5dbafca4",
      "e77848f1cd084209b56e9515808bc4d8",
      "48f12ab7c83143ab91ce5f0c7b696033",
      "f920da0f0a9e4d87b01c6dc1989e3b87",
      "265e30c312f648ddb2fe095d11c5768c",
      "5af491c61d1a4ab2a59a9dd9e7cb7b24",
      "7d80d9b449904cb29d157306f43725f4",
      "bc09c1246ed34a9b89d20311f29fe843",
      "0daf5fee0dcb4f4493d240d37ac2c921",
      "576f4b4606d24159925b80f6ed11fa00",
      "13c40ad246f1402b9433a1cab9ed3ed1",
      "1aa03c4cd63a4da99b650fbbc2204c87",
      "45519b3af35b4f0fa5c0c37849bdf3b4",
      "e97c02a734084758a24772cbd4d7addf",
      "b4c68535d48a42bd860d3bbb234d2f19",
      "45ed6dd37191465a80313d414d96df26",
      "5ef92bf1352045c7bbcc2d8869521061",
      "402d1c72e8fc4e9eb395ddd9b2a96ba9",
      "37a4c228b28245ac9fe119f938c9a739",
      "687a1eeda7144679a79759a91b2ad0d9",
      "90cd512737e94e9597a143ec416262b9",
      "a60e1ba7602a4fb4a729184aa5826213",
      "040c99f5fbc847fab9bc394e4fa899d3",
      "2054e28ff2744691bc621679d03d12bc",
      "208a510a99e841428234e9d2bcdadceb",
      "ba5971bf42a044af8b5c3d9180207a1d",
      "2f55c87b80f0406c9b6c55f816c185fd",
      "5497c5c5c2604fd0b2c159fca1f74c5d",
      "5e7f1f41b55a434c870d847a23a66eb4",
      "019624bd28664f9e8e270051e8b9ac96",
      "0534f970f4b643189ef6a24382430e6f",
      "41c54ea7e21a4f5f92a92c672785c041",
      "3adc3782f250474eb3663fe8965227ab",
      "ccfcc3c7db2e4cb69b4562ed843f75ba",
      "8ea6f6c710e1425d804ee5f2e0410f3e",
      "1b96fec918a546f0908ef69eec17e084",
      "bd96da4ec2654c43935ef275d0c1ff7b",
      "f55c60fe503d45bea1c0e6d51bfe6111",
      "7cadc88ed2d6405fa02d1bac53abce78",
      "14cf2edbc0274d6ebf35a686d8630ed9",
      "6da030bd2b1940ef91a668973e3d9e6c",
      "f0d6bb93afda48edb79fbd68dae956f4",
      "ce048016f1694093b51ad58a6d9e4cd7",
      "9ce28d6d13dc4e02a752206f9be4d4a0",
      "baaf88df1dc244749bfd09585943f4ef",
      "52c4f9009cc1454f837871f71eb1f15a",
      "a8a04971e50e4abfb438f36a0ccc2ad7",
      "8d1ac2e7a6bf49f28d929bc729cd532d",
      "a119000ffdeb45ffb65770bb5490a6ea",
      "92d61916933544c8958b2b951a14770d",
      "79fdde9283b941a7847a17d63ca76ae8",
      "5874eab0bbaa41d0a013974ddba9d432",
      "dfc5b5f358734ccb8617d903b61edbcd",
      "639e7cfad7864d8ab3bac0e34560e179",
      "5698c5e4e7a34de080e773d9b2efa334",
      "c7f7c1e0b7724a28982cab1177096f1c",
      "2422b0e2787b48c891ff98b0a014fd14",
      "a06e7034fd0f4582899d799563b00a65",
      "bf13e3768e0d41e9b022cc7b6abb2639",
      "d06be51d4d0b4e0a854e6a19d7762cfe",
      "8a52438ae21a40d882aad1cd3bd1312e",
      "8aa12803207b4aa0b1c678b8370cdfe5",
      "6f7695d6aef14c6fb362fed9b2911ab5",
      "b444f06350f7448ea174888e5f4026c5",
      "8f675bc5ffdb4588bf54538b7460dc69",
      "d2e5e033ac3242459b56ae071a4b4f02",
      "b33dc8d622aa4912ae45ceb74ed973a5",
      "642138f637044b609da364a9045b3999",
      "b580be4a1e1a4f728a938e0ebf235196",
      "53e1eab9f75f4687a7e020f70067f6c8",
      "38577daf287d46a194368a4379f6b6fe",
      "3b7484f1119448f49196becf0a56cf08",
      "d76762946a004c26ba63ac05105d18fe",
      "a9935a00d1454389a9742a4a22b6e5d8",
      "69368e9b7f8d4c8f80d42fb243cd125d",
      "44830aaf40fc4766a7591ac45383f858",
      "f606db6ec176456384091acd97832e1c",
      "0afbde4b671449939e30715c9b8bc91a",
      "af2fe165440b4406ba50433eab2a2a0c",
      "80e49e22daa04b12be52f8ae6ce318b2",
      "4471a5d7c4c840a7ac76980f71355bda"
     ]
    },
    "id": "4",
    "outputId": "2c94dfad-4474-4761-aaff-87b0532b1bcd"
   },
   "outputs": [],
   "source": [
    "raw_train = load_dataset(\"IlyaGusev/gazeta\")[\"train\"].to_pandas()\n",
    "raw_val = load_dataset(\"IlyaGusev/gazeta\")[\"validation\"].to_pandas()\n",
    "\n",
    "print(\"raw train shape:\", raw_train.shape, \"raw val shape:\", raw_val.shape)\n",
    "raw_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "5",
    "outputId": "e015998b-d45e-4726-e51e-fb0d20ccc7b4"
   },
   "outputs": [],
   "source": [
    "columns = [\"text\", \"summary\"]\n",
    "train = raw_train.loc[train_ids.squeeze(), columns]\n",
    "val = raw_val.loc[val_ids.squeeze(), columns]\n",
    "for col in columns:\n",
    "    train[col] = data_utils.clean(train[col])\n",
    "    val[col] = data_utils.clean(val[col])\n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6",
    "outputId": "0eed3712-732e-4822-c93d-7dc1d20bf30c"
   },
   "outputs": [],
   "source": [
    "MODEL_CFG_PATH = CONFIG_DIR / \"models.params.yml\"\n",
    "model_cfg = None\n",
    "if torch.cuda.is_available():\n",
    "    model_cfg = io_utils.load_yaml(MODEL_CFG_PATH)[\"cuda_model\"]\n",
    "else:\n",
    "    model_cfg = io_utils.load_yaml(MODEL_CFG_PATH)[\"cpu_model\"]\n",
    "\n",
    "model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "7",
    "outputId": "d9083e8c-750b-4cb4-a508-731f4467558a"
   },
   "outputs": [],
   "source": [
    "device = model_cfg[\"device\"]\n",
    "model_id = model_cfg[\"model_id\"]\n",
    "n_eval = model_cfg[\"n_eval\"]\n",
    "use_4bit = model_cfg[\"use_4bit\"]\n",
    "device_map = model_cfg[\"device_map\"]\n",
    "torch_dtype = (\n",
    "    torch.bfloat16\n",
    "    if device == \"cuda\" and torch.cuda.is_bf16_supported()\n",
    "    else (torch.float16 if device == \"cuda\" else torch.float32)\n",
    ")\n",
    "if n_eval is None:\n",
    "    subset_val = val\n",
    "else:\n",
    "    subset_val = val.sample(\n",
    "        n=min(n_eval, val.shape[0]), random_state=RANDOM_STATE\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "fewshot_pool = train.sample(\n",
    "    n=min(FEWSHOT_POOL_SIZE, len(train)), random_state=RANDOM_STATE\n",
    ").reset_index(drop=True)\n",
    "\n",
    "subset_val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "8"
   },
   "outputs": [],
   "source": [
    "quantization_config = None\n",
    "if use_4bit:\n",
    "    try:\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch_dtype,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"bitsandbytes не готов, продолжаем без 4-бит:\", e)\n",
    "        quantization_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "7eb8df94b5e7440ea5d706670d81050c",
      "6e7ec2971b0c434094d0b7009baf4f2a",
      "a3a81937e4dc4d3b8d3586465ea194ed",
      "09cd5b3ecc994c02a7550a030f106763",
      "20ce8fe219994ec283c02c03488834aa",
      "5cbbafef52a14969ab95854c8224563c",
      "931ca0a681144ebca04c843d99de2049",
      "100d8350de304f8eaba71a02f7ef022a",
      "f1d9beeb344b47f194b67a4e4973ecad",
      "f8582c8869734c66b183e384de74690f",
      "62c6a51b326d42218339f909a0ec5ceb"
     ]
    },
    "id": "9",
    "outputId": "0cba8877-d242-4ef2-870a-71e4ae2e9f20"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=(None if quantization_config else torch_dtype),\n",
    "    device_map=device_map,\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.truncation_side = \"left\"\n",
    "\n",
    "if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "if getattr(model, \"generation_config\", None) is not None:\n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "if device != \"cuda\":\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr(tokenizer, \"model_max_length\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_utils.max_len(fewshot_pool, tokenizer, \"text\"), data_utils.max_len(\n",
    "    fewshot_pool, tokenizer, \"summary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer.encode(subset_val.iloc[0][\"text\"], add_special_tokens=False)), len(\n",
    "    tokenizer.encode(subset_val.iloc[0][\"summary\"], add_special_tokens=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"Ты помощник по резюмированию русскоязычных новостей. \"\n",
    "    \"Сделай краткое, нейтральное резюме исходного текста (3–5 предложений). \"\n",
    "    \"Не добавляй фактов, которых нет в тексте.\"\n",
    ")\n",
    "\n",
    "GEN_EVAL = GenerationConfig(\n",
    "    max_new_tokens=200,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "MAX_INPUT_TOKENS = model_utils.get_max_input_tokens(tokenizer, GEN_EVAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_chat_fewshot(target_text: str, pool_df, k=FEWSHOT_K):\n",
    "    exemplars = model_utils.sample_exemplars(pool_df, k=k, random_state=RANDOM_STATE)\n",
    "\n",
    "    kk = len(exemplars)\n",
    "    tgt_text = target_text\n",
    "    while kk >= 0:\n",
    "        msgs = model_utils.assemble_msgs(exemplars[:kk], tgt_text, SYSTEM_PROMPT)\n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            msgs, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        ids = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)[\n",
    "            \"input_ids\"\n",
    "        ][0]\n",
    "        if len(ids) + OVERHEAD_BUDGET <= MAX_INPUT_TOKENS:\n",
    "            return msgs  # успешно\n",
    "        # Иначе пробуем уменьшить число примеров\n",
    "        kk -= 1\n",
    "        if kk < 0:\n",
    "            # крайний случай: вернём zero-shot\n",
    "            return [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Задача: кратко резюмируй.\\n\\nТекст статьи:\\n{target_text}\",\n",
    "                },\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_fewshot(texts, pool_df, batch_size=3, show_progress=True):\n",
    "    out = []\n",
    "    it = range(0, len(texts), batch_size)\n",
    "    if show_progress:\n",
    "        it = tqdm(\n",
    "            it,\n",
    "            total=math.ceil(len(texts) / batch_size),\n",
    "            desc=\"Generating (few-shot)\",\n",
    "            leave=False,\n",
    "        )\n",
    "\n",
    "    prompt_strs = []\n",
    "    for t in texts:\n",
    "        msgs = build_chat_fewshot(t, fewshot_pool, k=FEWSHOT_K)\n",
    "        s = tokenizer.apply_chat_template(\n",
    "            msgs, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        prompt_strs.append(s)\n",
    "\n",
    "    for i in it:\n",
    "        chunk = prompt_strs[i : i + batch_size]\n",
    "        inputs = tokenizer(\n",
    "            chunk,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            pad_to_multiple_of=8,\n",
    "            max_length=MAX_INPUT_TOKENS,\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(**inputs, generation_config=GEN_EVAL)\n",
    "\n",
    "        gen_ids = output_ids[:, inputs[\"input_ids\"].shape[1] :]\n",
    "        decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
    "        out.extend([d.strip() for d in decoded])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "referenced_widgets": [
      "b27e34eaf9ef4992b8d5ea4d1a254fac",
      "e15fe0b9c6594e12a1b88bc32c13f18c",
      "f4e0ab89529741cb809c9290f061e52d",
      "a8a455fe19744be3b861e524ed038382",
      "ee0995e493c345ca9b4520b79f3c75c2",
      "fd6f1745d8e843deb72e08405d3064c2",
      "3da0405e4cde47129fef283391e6ef73",
      "8cde45ba9dcf4ff7b13355ab32432c42",
      "6c1b2ff9c1844533b868f2b32097d581",
      "32ee71202cd24d76a59e0fe9de776f9c",
      "7b06b8f884e44b708f972f4990a2842f"
     ]
    },
    "id": "10",
    "outputId": "fa7e872f-b411-4230-dfb7-ddb185cfb364"
   },
   "outputs": [],
   "source": [
    "BATCH = 1 if device != \"cuda\" else 3\n",
    "texts = subset_val[\"text\"].tolist()\n",
    "refs = subset_val[\"summary\"].tolist()\n",
    "preds_few = generate_batch_fewshot(\n",
    "    texts, pool_df=fewshot_pool, batch_size=BATCH, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11",
    "outputId": "dd5d8d43-7268-4700-8ce7-73c0960f73c0"
   },
   "outputs": [],
   "source": [
    "preds_few[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12",
    "outputId": "faa16970-62bb-4f1d-ad95-adaf38f13796"
   },
   "outputs": [],
   "source": [
    "refs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "WgDrxGKWfVCx"
   },
   "outputs": [],
   "source": [
    "scores = data_utils.get_all_scores(preds_few, refs, device=device)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "14"
   },
   "outputs": [],
   "source": [
    "Path(METRIC_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_metrics = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"system\": \"few_shot\",\n",
    "            \"split\": \"validation_full\",\n",
    "            \"rouge1\": scores.get(\"rouge1\", 0.0),\n",
    "            \"rouge2\": scores.get(\"rouge2\", 0.0),\n",
    "            \"rougeL\": scores.get(\"rougeL\", 0.0),\n",
    "            \"rougeLsum\": scores.get(\"rougeLsum\", 0.0),\n",
    "            \"bertscore_precision\": scores.get(\"bertscore_precision\", 0.0),\n",
    "            \"bertscore_recall\": scores.get(\"bertscore_recall\", 0.0),\n",
    "            \"bertscore_f1\": scores.get(\"bertscore_f1\", 0.0),\n",
    "            \"avg_len_pred\": scores.get(\"avg_len_pred\", 0.0),\n",
    "            \"avg_len_ref\": scores.get(\"avg_len_ref\", 0.0),\n",
    "            \"len_ratio_pred_to_ref\": scores.get(\"len_ratio_pred_to_ref\", 0.0),\n",
    "            \"k\": None,\n",
    "            \"n_examples\": n_eval,\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "df_metrics.to_csv(\n",
    "    METRIC_DIR / f\"llm_zero_shot_validation_{device}_{n_eval}.csv\", index=False\n",
    ")\n",
    "\n",
    "df_sampels = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"title\": subset_val[\"title\"].head(3) if \"title\" in subset_val else [\"\"] * 3,\n",
    "            \"reference\": refs[:3],\n",
    "            \"prediction\": preds_few[:3],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "df_sampels.to_csv(\n",
    "    METRIC_DIR / f\"llm_zero_shot_examples_{device}.tsv\", sep=\"\\t\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "16"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "IGMliQPofLUy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (llm-news)",
   "language": "python",
   "name": "llm-news"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
