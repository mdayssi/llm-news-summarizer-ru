{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    GenerationConfig,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "import src.utils.data as data_utils\n",
    "import src.utils.io as io_utils\n",
    "import src.utils.models as model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "id": "1"
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# EXTERNAL = Path(os.getenv(\"EXTERNAL_STORAGE_DIR\"))\n",
    "ROOT = io_utils.repo_root()\n",
    "SPLIT_DIR = ROOT / \"data/splits\"\n",
    "CONFIG_DIR = ROOT / \"config\"\n",
    "METRIC_DIR = ROOT / \"metrics\"\n",
    "RANDOM_STATE = 42\n",
    "set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2",
    "outputId": "96215c52-778e-464c-9e65-ccf3059de1e3"
   },
   "outputs": [],
   "source": [
    "ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "3"
   },
   "outputs": [],
   "source": [
    "VAL_IDS_PATH = io_utils.load_yaml(CONFIG_DIR / \"dataset.ids.yml\")[\"splits_ids\"][\n",
    "    \"val_ids\"\n",
    "]\n",
    "val_ids = pd.read_csv(ROOT / VAL_IDS_PATH, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562,
     "referenced_widgets": [
      "15d1c644ad8b47529ebc7916323d6865",
      "53af62afa3c645aa91507d0fa666187a",
      "0ce3aa887dc14a028fd01b42b3d76c41",
      "6c8293d44f9441f5b7e54d7f1ba042db",
      "c42ee63b8ff142d9b74806e8db8313dd",
      "f33189cdecef468c93ff6cf5a3135246",
      "bc7e4918c801414d8f36eabfb033cd3f",
      "323ad3f8d8dc418796563d89f3396f67",
      "3f721607c79842d88694633f1033ec82",
      "3eef6ae24d8a4747a639f41d3b64e357",
      "e460647ad2a845ce83803b27258da90a",
      "8b2eed71e81a4f1f81a42ab550441952",
      "80b334c8a2f141a49641352e0d9d2446",
      "720728d072a94dce972cae624131097f",
      "23b73befab294e0889d5c272a535cc6e",
      "0f6b27702e1740ed90b49c478d4b265e",
      "e69246cc06ff464ba682e3c76cc67d97",
      "f30c8ee1fc0d4829ae6fbda49d3968cf",
      "d4f84969ea7249c9883aebc8e819295f",
      "4c6e47f2cf204a38815075eb66b9ef8c",
      "07493d8d01484052a5ba36a7fe691805",
      "19fde90ebf224a7d9e6291bb77919830",
      "40bd7aee1e704b0ebf3c9ac2632570f2",
      "8cfe6a1f949e45228eb1e352c61604e9",
      "a6bf149effab4ea0b7e119695395c5af",
      "d86c14c635f947fabddfdfd6dd49f714",
      "29a97d5425ad463d94ec9f7f37f6edbb",
      "080083a1810c49b1b6f2eac14d519428",
      "9b401095bd7b4cec94b989d30edad362",
      "995ebd60e91142f9b3e8eb4bcda0d777",
      "2df38349197841fa930d9a9791016124",
      "807c1df2b6fd488691e84ecc137bccc0",
      "2ff915d617584f279f935732111de40c",
      "134eaffec8cb4fce88f5ec1fb3217ac4",
      "3ed2ba9b89e343a1868a74894149d1fd",
      "3e80feb10db94f3085c5bbebe44ca72f",
      "dbe5d84d6ce044c2a98bd2bba6cb69b6",
      "6510e5e17f1c45a9b5a88b9b371e3cae",
      "eff7e9742b45478ab062f938e3a65c4a",
      "65bfbf6077634584b78aa5c74292cb56",
      "13c8ae3293eb40b888dfdf13e80b5636",
      "3abf5a4ed0e342079de1cbbd252825ce",
      "432fccf0dcb0426da86c669305a67be7",
      "2537ddded57c4b098da2d84a4abb41e0",
      "21801212c9ca4227afe3b098dc5829c2",
      "09a8d563e1924d618a2310245e0de45b",
      "86aaf497501d42bb924fd8e7786d2a0c",
      "5bd80bc16df24309901d8a70f6eff9c8",
      "a9910fadec534722949b2fa01b04450d",
      "102660f52bf249b8a87fbec9f966a6a8",
      "7aa20e4354744435b796b24c1fe95b53",
      "4209db0694534f10ae48a44c72de2519",
      "bac6b94471144f11a9ddd2400a61ec58",
      "38c596bbc17e49c4926a1b0eb3cfe9a1",
      "2562de416e8047eba857e33ccefe2a7f",
      "0fa4041612204f4395d354fb29f58d21",
      "1d872d5a3ec443bd97ea9cf7ed766e29",
      "28262001fd7b463f8c7a2da8f7bb38b8",
      "ac9d9f72ec7d48868e4a905515f54e8b",
      "49c566cc105047dc9db2a7e560483136",
      "7d4a8e1516ba4ae6827f47ef92dfc91a",
      "8b2a235927eb41dcaecdd052d4b44b91",
      "d442376da04f4c9fb5c66d087a68ff11",
      "638f839fdfef44c0b23f8ebffa674896",
      "898a5e9678a24433ba595e2e905789a9",
      "48fa810d8d08408398c48cecf1198fb3",
      "13f9dbf1d60740c69a593b10af1c7b36",
      "f40cd7c7d44e4d32a4fe0d5882a0d5da",
      "d175669635194095baffc9fbad0319cd",
      "ebc0e9f28e54424e8291740b4445bb4d",
      "6460ca02493b43f99fe03c410a663649",
      "bfbba743954e40f09dcd18a9cbf3a8ce",
      "7a098536fd2f4d9a8274679e27cd51b9",
      "6d9c9e3213dd4f5da8836e43d1e0f67f",
      "fae94853f6024601be42a852a9ac94d4",
      "966434550da84968bcbc216f421b74c7",
      "12d682fe94444c77ad09163ed170257b",
      "2af65e2792be43518c23ba9d42df1115",
      "41de1b72aae14ace81e9f4bdea1a3da5",
      "2d364d1ec1fb4d4b949ee9f80404c825",
      "2d676a8f0feb4fdab98c7732ac2955b9",
      "a604b767729f4d299802c794d196f33f",
      "3abe88c90ca74fd4a51b2c64fc15c7bb",
      "6160710bb9cc44388efb374dfdf138fd",
      "5f9bf3cf56b64fc2be098901c29d14ef",
      "af62d7fd2d1144eba649184db238ae20",
      "f3190802e5714bbfaea464c9f4096c04",
      "4da38b585ad14ce1ab8126d30f489551"
     ]
    },
    "id": "4",
    "outputId": "4e49f6bc-6220-4c82-a362-6bcdbffbfd71"
   },
   "outputs": [],
   "source": [
    "raw_val = load_dataset(\"IlyaGusev/gazeta\")[\"validation\"].to_pandas()\n",
    "\n",
    "print(\"raw val shape:\", raw_val.shape)\n",
    "raw_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "5",
    "outputId": "43f24b75-eaca-4f75-e0e9-6f814a0fb137"
   },
   "outputs": [],
   "source": [
    "val = raw_val.loc[val_ids.squeeze(), [\"title\", \"text\", \"summary\"]]\n",
    "for col in val.columns:\n",
    "    val[col] = data_utils.clean(val[col])\n",
    "val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6",
    "outputId": "de05fac3-e1a2-4afc-fb7f-7e9cb6682757"
   },
   "outputs": [],
   "source": [
    "MODEL_CFG_PATH = CONFIG_DIR / \"models.params.yml\"\n",
    "model_cfg = None\n",
    "if torch.cuda.is_available():\n",
    "    model_cfg = io_utils.load_yaml(MODEL_CFG_PATH)[\"cuda_model\"]\n",
    "else:\n",
    "    model_cfg = io_utils.load_yaml(MODEL_CFG_PATH)[\"cpu_model\"]\n",
    "\n",
    "model_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "7",
    "outputId": "2e6c2053-70f5-4328-d9d9-ac67e73a6a52"
   },
   "outputs": [],
   "source": [
    "device = model_cfg[\"device\"]\n",
    "model_id = model_cfg[\"model_id\"]\n",
    "n_eval = model_cfg[\"n_eval\"]\n",
    "use_4bit = model_cfg[\"use_4bit\"]\n",
    "device_map = model_cfg[\"device_map\"]\n",
    "torch_dtype = (\n",
    "    torch.bfloat16\n",
    "    if device == \"cuda\" and torch.cuda.is_bf16_supported()\n",
    "    else (torch.float16 if device == \"cuda\" else torch.float32)\n",
    ")\n",
    "if n_eval is None:\n",
    "    subset_val = val\n",
    "else:\n",
    "    subset_val = val.sample(n=min(n_eval, val.shape[0]), random_state=RANDOM_STATE)\n",
    "\n",
    "subset_val.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "8"
   },
   "outputs": [],
   "source": [
    "quantization_config = None\n",
    "if use_4bit:\n",
    "    try:\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch_dtype,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(\"bitsandbytes не готов, продолжаем без 4-бит:\", e)\n",
    "        quantization_config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433,
     "referenced_widgets": [
      "4b64bf9936b844eabfe9fe648206aa38",
      "55eca593c2194c829e1716b7008b3d43",
      "92856d7f503c4b77a9168d36e3e30771",
      "08d8b098e2fa4bacb7c3552ab8fb08ee",
      "b381b4fa24ac49c8810f1dcaf699bb13",
      "c77e19df3b9445e09ef2499176d98b26",
      "d3e775e3e2e64c15b89c4d8da1d69905",
      "2681156937e64274a00d4929a04ba564",
      "bdad0250d6dc4881bdf639f75acef43e",
      "ffda579473ed4a648c091036791c4dfc",
      "c9bd334dffe34d118569b944e32b87ae",
      "eb0a74430b34402586bc5d322785b33b",
      "d8337cc33ed04b22b2c25f1924b457c6",
      "f07c5fb883e848eea2cf8d130b96a1ae",
      "c3ddcf8e4306415ba11acff8284fadff",
      "5ef73e9b032447728836ed02eab95aca",
      "5091d558480548dc8676b2367166337a",
      "93e2866b511b47adb9d09ee7cb029de8",
      "8df8ef51700745dbaf385d9bd871e574",
      "fe5fac33820c40229fa2f0f6eefbe3c0",
      "126771dacffb44cbaeb254ac6a37b28f",
      "33dc81f3e6f54cd79f8df3bd988f8784",
      "61f55f2634aa4bbfa167c733564368db",
      "5908f18ab464422ebf86b76495d83dea",
      "9486727912174debba728005caba7558",
      "f5b8d3d2937e4ae7be3a157229e7beea",
      "5bd6b8290dba4643b526c63071989a72",
      "075bf6164f58406eba6936c0650743c0",
      "c7ab8448644649b3a4a836b0c880e85e",
      "6041ccbf337348a5a828fe1fef74169e",
      "15ff21bf7cef4aa1b77d7a94eac76f29",
      "098464ee794643618500dd1cd44b0283",
      "b446b5b82aa2439088fa3151216333f5",
      "f6f3959de90040309b10466bdca0706d",
      "3d258609083c4f479b0e4502d3636914",
      "2ac52cc9ec5f4ea196b1730f51a3f4e5",
      "7e27fcad46d94b35b61d4cb675082877",
      "213ee1d2c18340c79a5fc9c5ecb84737",
      "675951d01bc74af5b832267bfa0c11d0",
      "292c0341e8d1454389de34361f31adbb",
      "300d37ff530d4629bdb782506daad25b",
      "486a20601f4641518f9a27150357f0e1",
      "8ac4a44c34474d45b1aa0512ec4e6b44",
      "612e570e62934820b8729bf2c1b162de",
      "de626da44fb74b63b963f50cf85d4bce",
      "5eaeab38798d40f3af0817d1034512bf",
      "4c787aac6b614896873eebd48f91a821",
      "8c4cca6d776e4559868c52286a78ba2d",
      "eb6c69e537924cfe9ad688cead58c282",
      "f39d21efe46a430080cd44e8b14c186d",
      "536fa96fdb20430c8ad80b7f79f9e305",
      "dbbac88aed1e4b86a37b3399bb894cac",
      "9fdf3ab1a11a4871aea3b40d0ed33423",
      "af038ca4117844e29e508279c3d2686e",
      "492f7ea4151d423cbd0d4008486743bc",
      "84c39886aeaf441689c77cc8e851150c",
      "b8770d4a0eff4bfe993beafc14d4b6bc",
      "8ec02c3d3eaa4aefbf37e13d05dd3000",
      "622d1459d26245d09f7a63ec2461c2dc",
      "04131e2fd62a4fdc8ea3e319d421339c",
      "adff83945bec4a748a91ae2be05d552d",
      "dece8ebeb62e46519abc25fead7550d6",
      "211f5ed4ed8045fa9c0f4d3562bb35d9",
      "87610037f78349b281891aac781ddbc7",
      "fd59333110e24dc1a411f8dbdf72fabf",
      "f7ccdf25c4fa41f59d646043dfb78d89",
      "5a3abada9dfa491cb0a0cfaf6e288a07",
      "1528da0f3fcc41ed83b1160307b152a9",
      "925f738d1b4f448aa7edc484681c0626",
      "7679e22eebf3411a90cb379bc1ee2dcd",
      "c7e860e72c2d4c5bac81d59cd639faf1",
      "00dbdde4a9134f61a7870f65f8067aec",
      "32a82a050d29430384d976580b631b23",
      "c215c835c4694e478922b90d1d85d022",
      "1a4bbce388a142fd9b16309800c7e8ec",
      "5bc46c708e8743dab2fdf8f1f3f60d59",
      "6f40a739ac9d405aa5977f85c21e2763",
      "13e8050c7b804541a14531320e15f500",
      "e99934d5fe96478291b9a7d1740fb0fa",
      "cbe11fe9256b44c997678823f31bf453",
      "92ba81609a5048399d53733d2678c216",
      "77a1e53e9d7e4e1683e143f8b4933551",
      "5af404ecb4704c5e8fb9736c1cfa4cf3",
      "75d92dbf4e264fcbb69f563ea570f97c",
      "a34743df08ca4e47a5675bb96c5daed3",
      "4dc29c5343c246e4a3978533bd0db12b",
      "e6ffca87313744a0ace9c45f6238053a",
      "0ff9d3d6f9444cf19799ff9eee422c00",
      "90825beaa84942898200df04c8ecac9e",
      "ab15530eefe14e6180b317da7ac517ea",
      "53363a79c34f4cc58a8b22fe0c61ca40",
      "369e2dc3c2604b17b5f9a6a9267dd0bf",
      "2e4fa842aeaa4886a8667b6ffeaf40dd",
      "ed461ec0e7ed463f93d8a22c7698ab09",
      "8eb3d1656ec641d89da2761b358fa8b5",
      "e40a36bbd6b44acfa1fb910f264a940a",
      "3a8617986e0945678e41cdaa6d5d002f",
      "3bf0b3b63dbd42f9b54f8cd7e4849c81",
      "df3a2a8284884f7ca37c778ea13a5e34",
      "9bf63b3eebe3444f8a60bc788b981dcc",
      "e014fb573316476bae033ed9686cd8e6",
      "d60466c659fd4a03917ce759418be4c8",
      "7ef53dc328814fc2acf6d2fd10a66d61",
      "3310b6e23b1f4512abd5f366e2124f9e",
      "aba7861151ee4f859cad54184d8f50d4",
      "2b6e18658f2042cfb5532c56e365ae45",
      "a1e0a21eb07342febc92ce561152f92c",
      "e2e9f6fff5a645b9a6f0bc9216111f9b",
      "8555b34889ac427ea7497d4f4adb09aa",
      "6253215bb9104f51908c902ea2ba5b2c",
      "0e39c6d6f9bb4f9292024bedf65fc969",
      "35a7dfd058094911b9876ba85670ea8c",
      "7cc4eebb4892487990e8a888c933f8e1",
      "e8d0a80508404885b2f4ff24b3347b18",
      "171f4e10cfa04d6199dcd64227539c81",
      "cce8074fb9e94af7a45097bc70581f06",
      "320760cae2264f4b99f9b6dfbf6802fb",
      "0e026698472e4249bb1dac47ac97b5f4",
      "fbdf348fc6ff4bb3b941de021492aaa9",
      "9fc3fb7a278b454f9e2f4b403668cd97",
      "ffb4223d6db94747b5bb3c05d42b93c7",
      "6ef6356e5c994e48a4951d89416ec643",
      "df750ee95b674623b34e7af5b015a892",
      "785c97f7be6b4e9896d8b9dd8feef006",
      "d82c9611e4bd46c089784c4665dc4fd6",
      "700318a968614d4bae7cdd0a84eb7db7",
      "80b99418c5bf4cc4883227021311c93d",
      "b8ada04cc8eb42f69f1fdca7d5b32300",
      "563d4aff165d4ac3b05dbbe432b7cdc7",
      "f3860f8f18814c6bb20af04e83a76254",
      "4ee208a259c44f9ea9b5abd06cbd76ed",
      "db5986e50f40407f9a37016d1b9d9ed5",
      "1d8d54bdc9b44ff18227ad21eb86709b",
      "24528a1655814a8fb65071ae8296402a",
      "b946936d04664d38ad7cc7c3877ee839",
      "436d3d7c306c4025b92013fd63a4a930",
      "6430c462230944cf84380a85f0cf7613",
      "13adf7043baf49fc85f8fb376b9313f7",
      "6f3689716c104cc3854bde848a200c9e",
      "2d474005e3b24668a953d8365383a6b3",
      "180b09adf01941d38c6da39dce458b3a",
      "8cdfc4ff608949afab140d72eec36810",
      "61dabc8303d3493090a92719c86e079b"
     ]
    },
    "id": "9",
    "outputId": "2d42bdd4-b195-4336-b12b-9636d01fb232"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=(None if quantization_config else torch_dtype),\n",
    "    device_map=device_map,\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "# 1) для decoder-only нужно левое выравнивание\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "# 2) при обрезке важно сохранять «конец» промпта (там префикс ассистента)\n",
    "tokenizer.truncation_side = \"left\"\n",
    "\n",
    "# 3) если у модели нет отдельного PAD — используем EOS\n",
    "if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "if getattr(model, \"generation_config\", None) is not None:\n",
    "    model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "if device != \"cuda\":\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "referenced_widgets": [
      "887a0af16efc4f4caee5f95c319f350a",
      "7aa988aee5614ad1b590b5ec827606d4",
      "e5b6fb647aca40838826bca9c2f8f429",
      "3452e5e6cfcb428e87a9aa889d9cc039",
      "eae2ebc7ccf546aca8c35e4012fbe692",
      "28122ee004e44594a4f4e3a0375f371e",
      "7ac2eaac4cb7404a96004c2c759a64de",
      "f3cbbf4b73a140a992e72ebdafa7aaf5",
      "71f5baa0ab4f47d5a0b31a2623eca8eb",
      "364cd3a4cc40407da4ee8f40de5d50c2",
      "91d05bc3d9ba4849b3c470aef6225851"
     ]
    },
    "id": "10",
    "outputId": "2f4fbf02-26c0-4f96-c11e-e89a534d9184"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = (\n",
    "    \"Ты помощник по резюмированию русскоязычных новостей. \"\n",
    "    \"Сделай краткое, нейтральное резюме исходного текста (3–5 предложений). \"\n",
    "    \"Не добавляй фактов, которых нет в тексте.\"\n",
    ")\n",
    "\n",
    "GEN_EVAL = GenerationConfig(\n",
    "    max_new_tokens=160,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "# 1) для decoder-only нужно левое выравнивание\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "# 2) при обрезке важно сохранять «конец» промпта (там префикс ассистента)\n",
    "tokenizer.truncation_side = \"left\"\n",
    "\n",
    "# 3) если у модели нет отдельного PAD — используем EOS\n",
    "if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "MAX_INPUT_TOKENS = model_utils.get_max_input_tokens(tokenizer, GEN_EVAL)\n",
    "\n",
    "\n",
    "def build_chat(text: str):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Задача: кратко резюмируй.\\n\\nТекст статьи:\\n{text}\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "\n",
    "def generate_batch(\n",
    "    texts: list[str], batch_size: int = 1, show_progress: bool = True\n",
    ") -> list[str]:\n",
    "    out = []\n",
    "    model.eval()\n",
    "\n",
    "    it = range(0, len(texts), batch_size)\n",
    "    if show_progress:\n",
    "        it = tqdm(\n",
    "            it, total=math.ceil(len(texts) / batch_size), desc=\"Generating\", leave=False\n",
    "        )\n",
    "\n",
    "    # на всякий случай — паддинг токен\n",
    "    if tokenizer.pad_token_id is None and tokenizer.eos_token_id is not None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    for i in it:\n",
    "        chunk = texts[i : i + batch_size]\n",
    "\n",
    "        # 1) шаблон → строки\n",
    "        prompts = [\n",
    "            tokenizer.apply_chat_template(\n",
    "                build_chat(t), tokenize=False, add_generation_prompt=True\n",
    "            )\n",
    "            for t in chunk\n",
    "        ]\n",
    "\n",
    "        # 2) строки → тензоры (BatchEncoding / dict)\n",
    "        inputs = tokenizer(\n",
    "            prompts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            pad_to_multiple_of=8,\n",
    "            max_length=MAX_INPUT_TOKENS,\n",
    "        ).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                **inputs,\n",
    "                generation_config=GEN_EVAL,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                eos_token_id=getattr(tokenizer, \"eos_token_id\", None),\n",
    "            )\n",
    "\n",
    "        # вырезаем только ответ\n",
    "        gen_ids = output_ids[:, inputs[\"input_ids\"].shape[1] :]\n",
    "        decoded = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)\n",
    "        cleaned = [d.strip() for d in decoded]\n",
    "        out.extend(cleaned)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "BATCH = 1 if device != \"cuda\" else 6\n",
    "\n",
    "preds_llm = generate_batch(\n",
    "    subset_val[\"text\"].tolist(), batch_size=BATCH, show_progress=True\n",
    ")\n",
    "refs_llm = subset_val[\"summary\"].tolist()\n",
    "len(preds_llm), len(refs_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11",
    "outputId": "61e622cc-beea-4e44-a45e-2fd22adc7cf4"
   },
   "outputs": [],
   "source": [
    "preds_llm[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12",
    "outputId": "96e868df-6556-4ab8-f8db-03bc6efd597d"
   },
   "outputs": [],
   "source": [
    "refs_llm[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "13"
   },
   "outputs": [],
   "source": [
    "# rouge_scores = data_utils.get_rouge_f1(preds_llm, refs_llm)\n",
    "\n",
    "# rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411,
     "referenced_widgets": [
      "46eef8f1d6434d6f9eff3a1b84ec4a94",
      "dd32fcc0d407445aaae1d1f3ae746052",
      "f2633a2abd0d4ba5b5268b55b797ac90",
      "4023e338a5824a1bb7f8e157fe58cbb2",
      "2bcf90f8ec2d49e796289049fd9c3297",
      "84924a4f5e1548adb088830832d85f95",
      "72e962305a384459a817644dab425574",
      "517ff6134366406487bef3159e8f328e",
      "c20c0fd64fbb448bb9e8e3906f4ad766",
      "205c6df37e7f4132b07bccd568b96679",
      "19c07da0bde042b29bf91770289406dc",
      "f7b2c4ec087b405db0b55e25252cf2b8",
      "7f6652dda3dd4ac3b8d394a7e1f22e63",
      "5b2680641cfa4dccb240de826b9e320f",
      "6a87e67873144eb4ab346368cf4779d0",
      "21bf416fba164c62aadb15d72bd8bfda",
      "3297700a239b4ca4a5c88659095285e3",
      "c0a33794eae643f88e29ec53a31af033",
      "15521fdc1d55463f9265004499e0cbe1",
      "73854425e9f445ac971bfe3d29594b61",
      "df39674e55df45c6a76088f19027f355",
      "a6690420727a42e180a7f372e976a593",
      "ea9aedfebdc049f6a512f48aee5dbccc",
      "8cf29f52bd42459382f441414a48a30a",
      "9d1422c2a14b4cb386c4a143400b5124",
      "0d1729652f5d48f3baa97612f721a43f",
      "bcfe38091885410cb2253de6965d10c8",
      "be64484778284548a5599df6390e5b70",
      "72b606f6ac714671ba7c7ebdc8b9e916",
      "a607ec7bdd5b43e3a6691f36b7bb6084",
      "811f965d852749f881a6eb66549d51d2",
      "a4afde67f3db4dd393e5fc05cd3c6d53",
      "1cc8ab6b9be042688b33f5bafda5fcdb",
      "ee18113cd2754eabb00efbd02ecf1a19",
      "7b71faa82f0d47418aed214f3ae9586d",
      "b12dab24d1734d758883c694239ab6c3",
      "66e356b4fafc460381ec8aa1a59cc748",
      "b4bed53f4cdd440f924151387dfd5c3a",
      "94735c6c9bd6486381e7056dee1d881d",
      "4e1da95b6fa94c59b729b71589ca514a",
      "a915cb8a381c442c82eb5118ce204850",
      "163f7cd0b9a54e27a0b0700616fa570e",
      "121d1e816c2d4923a114035ab5e23e65",
      "ad60b532821844eab3547a0ab9faa3df",
      "2430f69249334a299b2da91e9c127eb0",
      "c626d6eae6504481a83bcc47600d7f42",
      "aec3f7e54cc446f296291794f48332c4",
      "49726165a5b64e3a9b26f01b2958e473",
      "b081322c866048d1b78ca55fb3c2e6b6",
      "d712d25895bd481f8276a78f150ccfad",
      "358347970cb9447998b109716a025c95",
      "41f2fd2bc3914d009a556c6c0bb61c21",
      "d8cebd2887a3439b87742188e743ad03",
      "f881f93e8b074f54b53a1da69d305ffb",
      "1742c1f2465d4babb56add68333fca4e",
      "485fa702c5144d039cbe9e7e035478b8",
      "bed1a6b76465416781953916e7a4e1b3",
      "f93042867fc9460687f2bab91a792e1f",
      "927b3f7ebcf04d049cc2075f11c27cda",
      "6ef1c51ba61a4ddebfc82928c67a7fdb",
      "caf443c35b424c21ad72e85ec3f74acd",
      "1d9678a68eb3407898c9b0a452575612",
      "e919cc6a2a624436af48ee91dbe35962",
      "32010ef81fd74a929bed7556a71cb841",
      "abecfd1d30a34637955499117f153892",
      "bb74b83b00f745c18de0645dddef860e",
      "9478864ff20f4621b62bfa7f956b5f66",
      "259cd2a138f44b869f787aa3aa4b75ee",
      "a6be9f877f3547b18f424311eedbed79",
      "11613e651a724e10aa2a73ce70134281",
      "4c18174aaf814faf8746f07e4fe99375",
      "cbabfbbbed3c44a9ae2070c8343ffc56",
      "947c524a500548158cf93a0f271b1f07",
      "5ae13dfcf6e34028888dae7177816ba2",
      "b3eee89695b8432b94284f7abc98d77f",
      "74b3e0d711824056bfa448548fd08b34",
      "8de46a64cff243cbaef4eafed6a74f44"
     ]
    },
    "id": "14",
    "outputId": "73b6fab4-a401-46dc-9d79-dba83d576bb3"
   },
   "outputs": [],
   "source": [
    "scores = data_utils.get_all_scores(preds_llm, refs_llm, device=device)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "id": "15"
   },
   "outputs": [],
   "source": [
    "Path(METRIC_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_metrics = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"system\": \"extractive_lead3\",\n",
    "            \"split\": \"validation_full\",\n",
    "            \"rouge1\": scores.get(\"rouge1\", 0.0),\n",
    "            \"rouge2\": scores.get(\"rouge2\", 0.0),\n",
    "            \"rougeL\": scores.get(\"rougeL\", 0.0),\n",
    "            \"rougeLsum\": scores.get(\"rougeLsum\", 0.0),\n",
    "            \"bertscore_precision\": scores.get(\"bertscore_precision\", 0.0),\n",
    "            \"bertscore_recall\": scores.get(\"bertscore_recall\", 0.0),\n",
    "            \"bertscore_f1\": scores.get(\"bertscore_f1\", 0.0),\n",
    "            \"avg_len_pred\": scores.get(\"avg_len_pred\", 0.0),\n",
    "            \"avg_len_ref\": scores.get(\"avg_len_ref\", 0.0),\n",
    "            \"len_ratio_pred_to_ref\": scores.get(\"len_ratio_pred_to_ref\", 0.0),\n",
    "            \"k\": None,\n",
    "            \"n_examples\": n_eval,\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "df_metrics.to_csv(\n",
    "    METRIC_DIR / f\"llm_zero_shot_validation_{device}_{n_eval}.csv\", index=False\n",
    ")\n",
    "\n",
    "df_sampels = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"title\": subset_val[\"title\"].head(3) if \"title\" in subset_val else [\"\"] * 3,\n",
    "            \"reference\": refs_llm[:3],\n",
    "            \"prediction\": preds_llm[:3],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "df_sampels.to_csv(\n",
    "    METRIC_DIR / f\"llm_zero_shot_examples_{device}.tsv\", sep=\"\\t\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "16"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "id": "17"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18",
    "outputId": "1c0bcd1a-f07d-40a5-cf7a-3c4a251907b3"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"torch:\", torch.__version__, \"| CUDA доступна:\", torch.cuda.is_available())\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\", force_remount=True)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "\n",
    "BASE = \"/content/drive/MyDrive/llm-news\"\n",
    "for sub in [\"models\", \"metrics\", \"hf_cache\"]:\n",
    "    os.makedirs(os.path.join(BASE, sub), exist_ok=True)\n",
    "\n",
    "print(\"Созданы/проверены папки:\", os.listdir(BASE))\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "REPO_URL = \"https://github.com/mdayssi/llm-news-summarizer-ru.git\"\n",
    "REPO_DIR = \"/content/llm-news\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "else:\n",
    "    print(\"Репозиторий уже есть:\", REPO_DIR)\n",
    "\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "!git rev-parse --short HEAD\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "env_path = Path(REPO_DIR) / \".env\"\n",
    "kv = {\n",
    "    \"EXTERNAL_MODELS_DIR\": \"/content/drive/MyDrive/llm-news/models\",\n",
    "    \"EXTERNAL_METRICS_DIR\": \"/content/drive/MyDrive/llm-news/metrics_big\",\n",
    "    \"EXTERNAL_CACHE_DIR\": \"/content/drive/MyDrive/llm-news/hf_cache\",\n",
    "}\n",
    "text = \"\\n\".join([f\"{k}={v}\" for k, v in kv.items()]) + \"\\n\"\n",
    "env_path.write_text(text, encoding=\"utf-8\")\n",
    "\n",
    "print(\".env создано:\")\n",
    "print(env_path.read_text())\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "%pip -q install --upgrade \\\n",
    "  evaluate rouge-score bert_score\\\n",
    "  razdel bitsandbytes\\\n",
    "  python-dotenv pyyaml \\\n",
    "\n",
    "import accelerate\n",
    "import bert_score\n",
    "import bitsandbytes\n",
    "import datasets\n",
    "import dotenv\n",
    "import evaluate\n",
    "import razdel\n",
    "import rouge_score\n",
    "import sentencepiece\n",
    "import torch\n",
    "import tqdm\n",
    "import transformers\n",
    "import yaml\n",
    "\n",
    "print(\"torch:\", torch.__version__, \"| cuda avail:\", torch.cuda.is_available())\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "print(\"datasets:\", datasets.__version__)\n",
    "print(\"evaluate:\", evaluate.__version__)\n",
    "\n",
    "# ----------------------------------------------------------------------------------\n",
    "import sys\n",
    "\n",
    "repo_src = \"/content/llm-news/src\"\n",
    "if repo_src not in sys.path:\n",
    "    sys.path.insert(0, repo_src)\n",
    "print(\"sys.path ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "19"
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------\n",
    "# !git config --global user.email \"dasha.morgalenko@gmail.com\"\n",
    "# !git config --global user.name \"mdayssi\"\n",
    "# !git remote set-url origin https://$GITHUB_TOKEN@github.com/mdayssi/llm-news-summarizer-ru.git\n",
    "\n",
    "# !git branch --show-current\n",
    "# !git remote -v\n",
    "# !git fetch origin\n",
    "# !git pull --rebase origin main\n",
    "\n",
    "\n",
    "# !git status\n",
    "# !git add .\n",
    "# !git commit -m \"add metrics zero-shot 7B on cuda\"\n",
    "# !git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "id": "UQZF_9x4LzFo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
